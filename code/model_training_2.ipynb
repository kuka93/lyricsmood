{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training/2\n",
    "\n",
    "### We use the stored files in the 'dataset' directory as our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "corpusdir = 'dataset/' # Directory of corpus.\n",
    "song_lyrics = PlaintextCorpusReader(corpusdir, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['happy', 'sad']\n",
    "documents = []\n",
    "\n",
    "for fileid in song_lyrics.fileids():\n",
    "    for category in categories:\n",
    "        if category in fileid:\n",
    "            if category == 'happy':\n",
    "                documents.append((list(song_lyrics.words(fileid)), 1))\n",
    "            else:\n",
    "                documents.append((list(song_lyrics.words(fileid)), 0))\n",
    "\n",
    "import random\n",
    "random.seed(12345)\n",
    "random.shuffle(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "\n",
    "# This function does all the textual preprocessing steps\n",
    "def preprocessing(string_to_process):\n",
    "    normalized_string = string_to_process.lower().replace(\"_\", \"\")\n",
    "    # 1. Tokenize it! This also removes non alphanumeric characters since we're tokenizing words only.\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(normalized_string)\n",
    "    \n",
    "    # 2. Remove stopwords\n",
    "    #filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    \n",
    "    # 3. Remove numbers\n",
    "    filtered_tokens = [word for word in tokens if not hasNumbers(word)]\n",
    "    \n",
    "    # 4. Stemm it!\n",
    "    stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    #stemmer = SnowballStemmer(\"english\")\n",
    "    #stemmer = LancasterStemmer()\n",
    "    #stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    \n",
    "    return stemmed_tokens\n",
    "    #return filtered_tokens\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 \n",
      "Document 200 \n",
      "Document 600 \n",
      "Document 800 \n",
      "Document 1000 \n",
      "Document 1200 \n",
      "Document 1400 \n",
      "Document 1600 \n",
      "Document 1800 \n",
      "Document 2000 \n",
      "Document 2200 \n",
      "Document 2400 \n",
      "Document 2600 \n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "preprocessed_documents = list()\n",
    "\n",
    "for document in documents:\n",
    "    i = documents.index(document)\n",
    "    if (i % 200 == 0):\n",
    "        print(\"Document %s \" % i)\n",
    "    document_text = ' '.join(document[0])\n",
    "    preprocessed_text = preprocessing(document_text)\n",
    "    preprocessed_documents.append((preprocessed_text, document[1]))\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As Feature Extraction, we use TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n",
      "2800\n",
      "Number of TFIDF Features: 149637\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "labels = []\n",
    "for doc in preprocessed_documents:\n",
    "    txt = \" \".join(doc[0])\n",
    "    corpus.append(txt)\n",
    "    labels.append(doc[1])\n",
    "print(len(corpus))\n",
    "print(len(labels))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_matrix=vectorizer.fit_transform(corpus).todense()\n",
    "tfidf_names=vectorizer.get_feature_names()\n",
    "print(\"Number of TFIDF Features: %d\"%len(tfidf_names)) #same info can be gathered by using tfidf_matrix.shape\n",
    "variables = tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We apply Chi-Square feature selection in order to reduce the number of features. We select 10000 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm selecting k best\n",
      "k best selected and saved\n",
      "fitting model\n"
     ]
    }
   ],
   "source": [
    "print(\"I'm selecting k best\")\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "selector = SelectKBest(chi2, k=10000)\n",
    "\n",
    "print(\"k best selected and saved\")\n",
    "print(\"fitting model\")\n",
    "selector = selector.fit(variables, labels)\n",
    "\n",
    "print(\"model fitted\")\n",
    "\n",
    "import pickle\n",
    "pickle.dump(vectorizer, open(\"vectorizer10000features2.pickle\", \"wb\"))\n",
    "pickle.dump(selector, open(\"selector10000features2.pickle\", \"wb\"))\n",
    "\n",
    "X_new = selector.transform(variables,labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "print(\"splitting\")\n",
    "variables_train, variables_test, labels_train, labels_test  =   train_test_split(X_new, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We save the numpy arrays containing variables/labels train/test in order to load them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (2240, 10000)\n",
      "Shape of Test Data: (560, 10000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('variables_train_10000.npy', variables_train)\n",
    "np.save('variables_test_10000.npy', variables_test)\n",
    "np.save('labels_train_10000.npy', labels_train)\n",
    "np.save('labels_test_10000.npy', labels_test)\n",
    "#variables_train = np.load('variables_train_10000.npy')\n",
    "#variables_test = np.load('variables_test_10000.npy')\n",
    "#labels_train = np.load('labels_train_10000.npy')\n",
    "#labels_test = np.load('labels_test_10000.npy')\n",
    "\n",
    "print('Shape of Training Data: '+str(variables_train.shape))\n",
    "print('Shape of Test Data: '+str(variables_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Accuracy Score: 0.887500\n",
      "Classification Metrics: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.90      0.89       285\n",
      "          1       0.90      0.87      0.88       275\n",
      "\n",
      "avg / total       0.89      0.89      0.89       560\n",
      "\n",
      "Accuracy: 0.87 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import cross_validation\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "bnb_classifier=BernoulliNB()\n",
    "bnb_classifier=bnb_classifier.fit(variables_train,labels_train)\n",
    "bnb_predictions=bnb_classifier.predict(variables_test)\n",
    "nb_ascore=sklearn.metrics.accuracy_score(labels_test, bnb_predictions)\n",
    "print(\"Bernoulli Naive Bayes Accuracy Score: %f\" %nb_ascore)\n",
    "print(\"Classification Metrics: \")\n",
    "print(sklearn.metrics.classification_report(labels_test,bnb_predictions))\n",
    "cv_scores = cross_validation.cross_val_score(bnb_classifier, variables_train, labels_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'finalized_model_BernoulliNB_10000.sav'\n",
    "pickle.dump(bnb_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy Score: 0.844643\n",
      "Classification Metrics: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.92      0.86       285\n",
      "          1       0.91      0.76      0.83       275\n",
      "\n",
      "avg / total       0.85      0.84      0.84       560\n",
      "\n",
      "Accuracy: 0.81 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mn_bayes=MultinomialNB()\n",
    "mn_bayes_fit=mn_bayes.fit(variables_train,labels_train)\n",
    "prediction_mn=mn_bayes_fit.predict(variables_test)\n",
    "mn_ascore=sklearn.metrics.accuracy_score(labels_test, prediction_mn) \n",
    "print(\"Multinomial Naive Bayes Accuracy Score: %f\" %mn_ascore)\n",
    "print(\"Classification Metrics: \")\n",
    "print(sklearn.metrics.classification_report(labels_test,prediction_mn))\n",
    "cv_scores = cross_validation.cross_val_score(mn_bayes, variables_train, labels_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "#filename2 = 'finalized_model_MultinomialNB_10000.sav'\n",
    "#pickle.dump(mn_bayes, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forests Classifier: 0.732143\n",
      "Classification Metrics: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.74      0.74       285\n",
      "          1       0.73      0.72      0.73       275\n",
      "\n",
      "avg / total       0.73      0.73      0.73       560\n",
      "\n",
      "Accuracy: 0.71 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier=RandomForestClassifier(n_estimators=50)\n",
    "rf_classifier=rf_classifier.fit(variables_train,labels_train)\n",
    "rf_predictions=rf_classifier.predict(variables_test)\n",
    "acc=sklearn.metrics.accuracy_score(labels_test, rf_predictions)\n",
    "print (\"Accuracy Score of Random Forests Classifier: %f\" %acc)\n",
    "print(\"Classification Metrics: \")\n",
    "print(sklearn.metrics.classification_report(labels_test,rf_predictions))\n",
    "cv_scores = cross_validation.cross_val_score(rf_classifier, variables_train, labels_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "#filename2 = 'finalized_model_RandomForest_10000.sav'\n",
    "#pickle.dump(rf_classifier, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forests Classifier: 0.798214\n",
      "Classification Metrics: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.96      0.83       285\n",
      "          1       0.95      0.63      0.75       275\n",
      "\n",
      "avg / total       0.83      0.80      0.79       560\n",
      "\n",
      "Accuracy: 0.73 (+/- 0.16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "svm_classifier=linear_model.SGDClassifier(loss='hinge',alpha=0.0001)\n",
    "svm_classifier=svm_classifier.fit(variables_train, labels_train)\n",
    "svm_predictions=svm_classifier.predict(variables_test)\n",
    "acc=sklearn.metrics.accuracy_score(labels_test, svm_predictions)\n",
    "print (\"Accuracy Score of Random Forests Classifier: %f\" %acc)\n",
    "print(\"Classification Metrics: \")\n",
    "print(sklearn.metrics.classification_report(labels_test,svm_predictions))\n",
    "cv_scores = cross_validation.cross_val_score(svm_classifier, variables_train, labels_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "filename2 = 'finalized_model_SVM_10000.sav'\n",
    "pickle.dump(svm_classifier, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear SVM Classifier: 0.812500\n",
      "Classification Metrics: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.77      0.81       285\n",
      "          1       0.78      0.85      0.82       275\n",
      "\n",
      "avg / total       0.82      0.81      0.81       560\n",
      "\n",
      "Accuracy: 0.71 (+/- 0.15)\n"
     ]
    }
   ],
   "source": [
    "svm_classifier_enet=linear_model.SGDClassifier(loss='hinge',alpha=0.0001,penalty='elasticnet')\n",
    "svm_classifier_enet=svm_classifier_enet.fit(variables_train, labels_train)\n",
    "svm_enet_predictions=svm_classifier_enet.predict(variables_test)\n",
    "print (\"Accuracy Score of Linear SVM Classifier: %f\"%sklearn.metrics.accuracy_score(labels_test,svm_enet_predictions))\n",
    "print(\"Classification Metrics: \")\n",
    "print(sklearn.metrics.classification_report(labels_test,svm_enet_predictions))\n",
    "cv_scores = cross_validation.cross_val_score(svm_classifier_enet, variables_train, labels_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "filename2 = 'finalized_model_SVMenet_10000.sav'\n",
    "pickle.dump(svm_classifier_enet, open(filename2, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM Classifier: 0.839286\n",
      "Classification Metrics: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84       285\n",
      "          1       0.83      0.85      0.84       275\n",
      "\n",
      "avg / total       0.84      0.84      0.84       560\n",
      "\n",
      "Accuracy: 0.81 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "cl = SVC(C=100.0, gamma=0.01, kernel='rbf')\n",
    "cl.fit(variables_train, labels_train)\n",
    "pred=cl.predict(variables_test)\n",
    "print (\"Accuracy Score of SVM Classifier: %f\"%sklearn.metrics.accuracy_score(labels_test,pred))\n",
    "print(\"Classification Metrics: \")\n",
    "print(sklearn.metrics.classification_report(labels_test,pred))\n",
    "cv_scores = cross_validation.cross_val_score(cl, variables_train, labels_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "filename2 = 'finalized_model_SVC_10000.sav'\n",
    "pickle.dump(cl, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'gamma': 0.01, 'C': 100.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "parameters = {'kernel': ['rbf'], 'C': [0.1, 1.0, 10.0, 100.0], 'gamma': [10, 1, 0.1, 0.01, 0.001]}\n",
    "cl = SVC()\n",
    "clf = grid_search.GridSearchCV(cl, parameters)\n",
    "clf.fit(variables_train, labels_train)\n",
    "print(clf.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
